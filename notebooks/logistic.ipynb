{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using logistic regression\n",
    "For this exercise we'll be using [scikit-learn](https://scikit-learn.org/stable/). This is great library/module for predictive data analysis in Python. It's got a huge library of algorithms and models, from standard linear models like regression, to Support Vector Machines, Decision Trees, and Neural Networks. We'll start with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of image data\n",
    "When working with images in machine learning, it's common to apply some kind of normalization to the pixel values.\n",
    "One of the common ways to normalize image data is to scale the values to the [0, 1] interval. This is what we will do here,\n",
    "using min-max scaling.\n",
    "Min-max scaling preserves the shape of the distribution, so that the difference between each image in\n",
    "a set of images is also preserved. In doing so, we are assuming that this property in the data is important,\n",
    "but keep in mind that it is something we can change, should we want to.\n",
    "Min-max scaling is calculated as\n",
    "$$\\text{scaled image} = \\frac{\\text{image} - \\mu_{image}}{I_{max} - I_{min}},$$\n",
    "where $I_{max}$ and $I_{min}$ refer to the maximum and minimum pixel intensity,\n",
    "and $\\mu_{image}$ is the mean pixel intensity for the set of images.\n",
    "\n",
    "We'll implement this as a function `normalize_image_data()`.\n",
    "However, we're not going to use it quite yet. We won't apply normalization to the data before we've split it into\n",
    "a training set and a validation set. If we normalize the entire dataset, then split it, we've techinically\n",
    "included properties of the validation set in the training set. This can give you a false picture of how well\n",
    "your model is performing, and should be avoided.\n",
    "\n",
    "Note that sklearn has a function for this too, an entire library for data preprocessing, actually.\n",
    "Check it out [here](https://scikit-learn.org/stable/modules/preprocessing.html).\\\n",
    "We're also going to save this normalization function to a separate python file called `helper_functions.py`.\n",
    "That way, we don't need to define it in every single notebook we make. We can just import it from that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization function\n",
    "def normalize_image_data(images):\n",
    "    \"\"\" Takes an imported set of images and normalizes values to between\n",
    "    0 and 1 using min-max scaling across the whole image set.\n",
    "    \"\"\"\n",
    "    img_term = np.amax(images) - np.amin(images)\n",
    "    img_mean = np.mean(images)\n",
    "    images = (images - img_mean) / img_term\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels.\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "images = np.load(DATA_PATH+\"images_training.npy\")\n",
    "labels = np.load(DATA_PATH+\"labels_training.npy\")\n",
    "\n",
    "# Split the training indices into training and validation. \n",
    "# Validate with 25% of the data (default). Can be adjusted.\n",
    "x_idx = np.arange(images.shape[0])\n",
    "train_idx, val_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit to the training data\n",
    "The documentation for the LogistigRegression class is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression).\n",
    "\n",
    "We'll start off with the default settings for the algorithm, and once we've got everything working we'll take a look\n",
    "at tuning the *hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init logreg class and fit to the training data.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# We pass normalized image data to the function.\n",
    "logreg.fit(normalize_image_data(images[train_idx]), labels[train_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7271111111111112\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation data. score() returns the mean accuracy on the provided validation data and labels\n",
    "acc = logreg.score(normalize_image_data(images[val_idx]), labels[val_idx])\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
