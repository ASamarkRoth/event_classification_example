{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying simulated events using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import import_data, normalize_image_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels.\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "images = np.load(DATA_PATH+\"images_training.npy\")\n",
    "labels = np.load(DATA_PATH+\"labels_training.npy\")\n",
    "\n",
    "# Split the training indices into training and validation. \n",
    "# Validate with 25% of the data (default). Can be adjusted.\n",
    "x_idx = np.arange(images.shape[0])\n",
    "train_idx, val_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Now, you can build your own network from scratch, and that's a useful exercise. We're going to skip that\n",
    "here, and use one of the popular, exisiting frameworks that are widely used in current research.\n",
    "The most used base frameworks are [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), and [Keras](https://keras.io/). Keras is a high-level API that abstracts a large amount of the process of building,\n",
    "training, and testing a model. You will need either TensorFlow or PyTorch, and the Keras API will automatically\n",
    "detect which base framework you have.\n",
    "\n",
    "In this example we use TensorFlow (TF). TF also incorporates the keras API in it's own package,\n",
    "which we will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary TF models and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Sequential model, and add layers to it.\n",
    "model = Sequential()\n",
    "\n",
    "# The model we build here is the one that has currently performed best when classifying the detector images.\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(16, 16, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the model is built, we need to compile it. This is where we specify the loss function,\n",
    "# optimizer, and any metrics we need, even custom ones.\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This is the point where we normalize our data, just as we pass it to the training function of the model.\n",
    "The training run will display the progress as it goes through each batch.\n",
    "$$ \\text{num_batches} = \\frac{\\text{num_samples}}{\\text{batch_size}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the training.\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4688/4688 [==============================] - 42s 9ms/step - loss: 0.6931 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5053\n",
      "Epoch 2/10\n",
      "4688/4688 [==============================] - 42s 9ms/step - loss: 0.6931 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4991\n",
      "Epoch 3/10\n",
      "4688/4688 [==============================] - 42s 9ms/step - loss: 0.6931 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.4977\n",
      "Epoch 4/10\n",
      "4688/4688 [==============================] - 44s 9ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 5/10\n",
      "4688/4688 [==============================] - 42s 9ms/step - loss: 0.6931 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 6/10\n",
      "4688/4688 [==============================] - 43s 9ms/step - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.4971\n",
      "Epoch 7/10\n",
      " 709/4688 [===>..........................] - ETA: 32s - loss: 0.6931 - accuracy: 0.5020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8297bdd3cf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setting validation data requires a tuple (val_input, val_targets). You can also just pass the\n",
    "# entire training set without splitting, and specify validation_split instead of validation_data.\n",
    "# The the model handles the splitting.\n",
    "\n",
    "val_data = (normalize_image_data(images[val_idx]), labels[val_idx])\n",
    "model.fit(\n",
    "    x=normalize_image_data(images[train_idx]),\n",
    "    y=labels[train_idx],\n",
    "    validation_data=val_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y_true = y_test.argmax(axis=-1)\n",
    "tmp_predicted = loaded_model.predict(x_test)\n",
    "y_pred = tmp_predicted.argmax(axis=-1)\n",
    "\n",
    "# indices, relative distances and relative energies for test set\n",
    "single_indices, double_indices, close_indices = event_indices(test_positions)\n",
    "rel_distance_test = relative_distance(test_positions)\n",
    "energy_diff_test = energy_difference(test_energies)\n",
    "rel_energy_test = relative_energy(test_energies, noscale=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some numbers from results\n",
    "Mean separation distances, mean relative energies, events with separation < 3mm etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate correct and wrong classifications\n",
    "correct_doubles = np.where(y_pred[double_indices] == 1)[0]\n",
    "wrong_doubles = np.where(y_pred[double_indices] == 0)[0]\n",
    "correct_close_doubles = np.where(y_pred[close_indices] == 1)[0]\n",
    "\n",
    "# Mean distances\n",
    "mean_dist_correct = np.mean(rel_distance_test[double_indices][correct_doubles])\n",
    "mean_dist_wrong = np.mean(rel_distance_test[double_indices][wrong_doubles])\n",
    "mean_dist_all = np.mean(rel_distance_test[double_indices])\n",
    "\n",
    "# Mean energies\n",
    "mean_energy_all = np.mean(rel_energy_test[double_indices])\n",
    "mean_energy_correct = np.mean(rel_energy_test[double_indices][correct_doubles])\n",
    "mean_energy_wrong = np.mean(rel_energy_test[double_indices][wrong_doubles])\n",
    "\n",
    "\n",
    "# Ratios\n",
    "ratio_doubles = len(correct_doubles) / len(double_indices)\n",
    "ratio_close = len(correct_close_doubles) / len(close_indices)\n",
    "\n",
    "\n",
    "# Output\n",
    "print(\"Number of events:\")\n",
    "print(\"Single: {} \\nDouble: {} \\nClose: {}\\n\".format(\n",
    "    len(single_indices),\n",
    "    len(double_indices),\n",
    "    len(close_indices))\n",
    "     )\n",
    "print(\"Mean separations for classified double events:\")\n",
    "print(\"All doubles: {:.2f}mm \\nCorrect: {:.2f}mm \\nWrong: {:.2f}mm\\n\".format(\n",
    "    mean_dist_all,\n",
    "    mean_dist_correct,\n",
    "    mean_dist_wrong)\n",
    "     )\n",
    "\n",
    "print(\"Mean relative energy for classified double events:\")\n",
    "print(\"All doubles: {:.2f} \\nCorrect: {:.2f} \\nWrong: {:.2f}\\n\".format(\n",
    "    mean_energy_all,\n",
    "    mean_energy_correct,\n",
    "    mean_energy_wrong)\n",
    "     )\n",
    "print(\"Ratios of correctly classified double events:\")\n",
    "print(\"All doubles: {:.3f} \\nClose: {:.3f}\\n\".format(\n",
    "    ratio_doubles,\n",
    "    ratio_close)\n",
    "     )\n",
    "\n",
    "print(\"Ratio of correct singles: %.3f\" % (19749/len(single_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "The confusion matrix can be a useful metric to gain a little bit\n",
    "more insight into specifically what the model gets wrong.\n",
    "* Top left: Single events classified as single events\n",
    "* Top right: Single events classified as double events\n",
    "* Bottom left: Double events classified as single events\n",
    "* Bottom right: Double events classified as double events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from analysis_functions.plotting import plot_confusion_matrix\n",
    "classes = [\"single\", \"double\"]\n",
    "title = net +\" Confusion Matrix\"\n",
    "plot_confusion_matrix(y_true, y_pred, classes, title=title)\n",
    "plt.show()\n",
    "#plt.savefig(FIGURE_PATH+net+\"_confmat.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(y_true, y_pred)\n",
    "print(\"F1-score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves\n",
    "#### All events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from analysis_functions.plotting import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plot_roc_curve(y_true, tmp_predicted[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Area under curve:\",roc_auc_score(y_true, tmp_predicted[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_close_true = np.concatenate((y_true[single_indices], y_true[close_indices]), axis=0)\n",
    "single_close_pred = np.concatenate((tmp_predicted[single_indices,1], tmp_predicted[close_indices,1]), axis=0)\n",
    "plot_roc_curve(single_close_true, single_close_pred)\n",
    "plt.show()\n",
    "print(\"Area under curve:\",roc_auc_score(single_close_true, single_close_pred))\n",
    "single_close_pred = np.concatenate((y_pred[single_indices], y_pred[close_indices]), axis=0)\n",
    "score_close = f1_score(single_close_true, single_close_pred)\n",
    "print(\"F1-score close: \", score_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions and scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing correct and misclassified double events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, np.amax(energy_diff_test), 0.02)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of separation distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Separation distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, 10, 0.1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "#ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of Relative distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Relative distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "#ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "#ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot relative distance vs. relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    rel_distance_test[double_indices][wrong_doubles], \n",
    "    rel_energy_test[double_indices][wrong_doubles],\n",
    "    marker='.',\n",
    "    )\n",
    "plt.title(\"Separation distance vs. relative energy for misclassified double events\")\n",
    "plt.xlabel(\"Separation distance [mm]\")\n",
    "plt.ylabel(\"Relative energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events with high separation distance\n",
    "and varying relative energy above a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the indices\n",
    "separation_lim = 20.0\n",
    "energy_lim = 0.2\n",
    "high_relD = np.where(rel_distance_test[double_indices][wrong_doubles] > separation_lim)[0]\n",
    "high_relE = np.where(rel_energy_test[double_indices][wrong_doubles] > energy_lim)[0]\n",
    "\n",
    "# Then get the overlapping indices\n",
    "high_both = np.array(list(set(high_relD).intersection(set(high_relE))))\n",
    "print(\"Found {} events.\".format(len(high_both)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the indices to fetch the images and other statistics we want.\n",
    "images_plot_high = images[test_idx][double_indices][wrong_doubles][high_both][:,:,:,0]\n",
    "rel_pos_plot_high = rel_distance_test[double_indices][wrong_doubles][high_both]\n",
    "rel_energy_plot_high = rel_energy_test[double_indices][wrong_doubles][high_both]\n",
    "energy_plot_high = energies[test_idx][double_indices][wrong_doubles][high_both]\n",
    "\n",
    "# Plot the events images with relative separation, energies, and relative energy\n",
    "# to the top left of each image\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12,12))\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        if i*2+j >= len(high_both):\n",
    "            fig.delaxes(ax.flatten()[i*2 + j])\n",
    "            continue\n",
    "        ax[i, j].imshow(images_plot_high[i*2 + j])\n",
    "        rel_pos = rel_pos_plot_high[i*2 + j]\n",
    "        rel_E = rel_energy_plot_high[i*2 + j]\n",
    "        E1 = energy_plot_high[i*2 + j, 0]\n",
    "        E2 = energy_plot_high[i*2 + j, 1]\n",
    "        relp = \"dist = {:.2f}mm\".format(rel_pos[0])\n",
    "        rele = \"rel_E = {:.2f}\".format(rel_E[0])\n",
    "        e1_txt = \"E1 = {:.2f} MeV\".format(E1)\n",
    "        e2_txt = \"E2 = {:.2f} MeV\".format(E2)\n",
    "        ax[i, j].text(-10, 0, relp, fontsize=11)\n",
    "        ax[i, j].text(-10, 1, e1_txt, fontsize=11)\n",
    "        ax[i, j].text(-10, 2, e2_txt, fontsize=11)\n",
    "        ax[i, j].text(-10, 3, rele, fontsize=11)\n",
    "        \n",
    "fig.suptitle(\"Misclassified events with large separation distance\", fontsize=16)\n",
    "#fig.savefig(FIGURE_PATH+net+\"_misclassified_large_dist.pdf\", format=\"pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of events that no networks were able to classify correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indices\n",
    "OUTPUT_PATH = MODEL_PATH = \"../../data/output/\"\n",
    "fname_indices = \"never_correct_indices_rerun.txt\"\n",
    "never_correct = np.loadtxt(OUTPUT_PATH + fname_indices, dtype=int).tolist()\n",
    "\n",
    "rel_distance_all = relative_distance(positions)\n",
    "rel_energy_all = relative_energy(energies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions for relative distance and relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate bins\n",
    "dist_bins = np.arange(0, np.amax(rel_distance_all), 0.5)\n",
    "energy_bins = np.arange(0, np.amax(rel_energy_all), 0.02)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "ax[0].hist(rel_distance_all[never_correct], bins=dist_bins)\n",
    "ax[0].set_title(\"Distribution of relative distance\\n for always misclassified events\")\n",
    "ax[0].set_xlabel(\"Relative distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(rel_energy_all[never_correct], bins=energy_bins)\n",
    "ax[1].set_title(\"Distribution of relative energy\\n for always misclassified events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "\n",
    "#fig.savefig(FIGURE_PATH+net+\"_relative_noncorrect.pdf\", format=\"pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images of some of the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of always misclassified events:\", len(never_correct))\n",
    "\n",
    "images_plot = images[never_correct][:,:,:,0]\n",
    "rel_dist_plot = rel_distance_all[never_correct]\n",
    "rel_energy_plot = rel_energy_all[never_correct]\n",
    "energy_plot = energies[never_correct]\n",
    "fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "index = 10\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].imshow(images_plot[index + i*3 + j])\n",
    "        rel_dist = rel_dist_plot[index + i*3 + j]\n",
    "        rel_energy = rel_energy_plot[index + i*3 + j]\n",
    "        E1 = energy_plot[i*3 + j, 0]\n",
    "        E2 = energy_plot[i*3 + j, 1]\n",
    "        rel_d = \"rel_dist = {:.2f}mm\".format(rel_dist[0])\n",
    "        rel_e = \"rel_E = {:.2f}\".format(rel_energy[0])\n",
    "\n",
    "        e1_txt = \"E1 = {:.2f} MeV\".format(E1)\n",
    "        e2_txt = \"E2 = {:.2f} MeV\".format(E2)\n",
    "        ax[i, j].text(0,-2, rel_d, color='black', fontsize=11)\n",
    "        ax[i, j].text(0,-1, rel_e, color='black', fontsize=11)\n",
    "        ax[i, j].text(0,1, e1_txt, color='cyan', fontsize=11)\n",
    "        ax[i, j].text(0,2, e2_txt, color='cyan', fontsize=11)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Images of always misclassified double events\", fontsize=16)\n",
    "#fig.savefig(FIGURE_PATH+net+\"_nocorrect_samples.pdf\", format=\"pdf\")\n",
    "\n",
    "fig.show()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some images, with electron origin positions\n",
    "%matplotlib inline\n",
    "\n",
    "images = images.reshape(images.shape[0],16,16)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # plot image\n",
    "        ax[i, j].imshow(images[index + i*3 + j])\n",
    "        \n",
    "        # plot origin of event\n",
    "        x = positions[index + i*3 + j, 0]\n",
    "        y = positions[index + i*3 + j, 1]\n",
    "        ax[i, j].plot(x, y, 'rx')\n",
    "        ax[i, j].set_title('single')\n",
    "        if positions[index + i*3 + j, 3] != -100:\n",
    "            x2 = positions[index + i*3 + j, 2]\n",
    "            y2 = positions[index + i*3 + j, 3]\n",
    "            ax[i, j].plot(x2, y2, 'rx')\n",
    "            ax[i, j].set_title('double')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of position around highest intensity pixel\n",
    "In previous work data analysis showed that most event positions are within the highest intensity pixel,\n",
    "and all (verify!) events are within the two highest intensity pixels,\n",
    "It might be reasonable to look at how the predicted positions are distributed around the highest intensity\n",
    "pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = images[single_indices].reshape(images[single_indices].shape[0],16,16)\n",
    "\n",
    "# get index of highest energy pixel\n",
    "print(np.unravel_index(np.argmax(imgs[0], axis=None), imgs[0].shape))\n",
    "fix, ax = plt.subplots()\n",
    "ax.imshow(imgs[0])\n",
    "ax.plot(0,0, 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"DATA_PATH\": \"../../data/real/anodedata.txt\",              \n",
    "    \"MODEL_PATH\": \"../../data/output/models/\",                \n",
    "    \"CLASSIFIER\": \"Project-0.97.hdf5\",                      \n",
    "    \"SINGLE_ENERGY_MODEL\": \"single_energy_model_name.hdf5\",    \n",
    "    \"SINGLE_POSITION_MODEL\": \"single_position_model_name.hdf5\",\n",
    "    \"DOUBLE_ENERGY_MODEL\": \"double_energy_model_name.hdf5\",    \n",
    "    \"DOUBLE_POSITION_MODEL\": \"double_position_model_name.hdf5\" \n",
    "}\n",
    "\n",
    "data = import_real_data(config)\n",
    "print(data['image'].type)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
