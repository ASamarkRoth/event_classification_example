{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying simulated events using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import import_data, normalize_image_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels.\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "images = np.load(DATA_PATH+\"images_training.npy\")\n",
    "labels = np.load(DATA_PATH+\"labels_training.npy\")\n",
    "\n",
    "# Split the training indices into training and validation. \n",
    "# Validate with 25% of the data (default). Can be adjusted.\n",
    "x_idx = np.arange(images.shape[0])\n",
    "train_idx, val_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping data for CNNs\n",
    "The convolutional layers we'll be using expect the inputs to have 4 dimensions:\\\n",
    "(samples, M, N, channels).\\\n",
    "M and N are the image dimensions, 16x16, but while RGB images have 3 channels, ours currently has 0, but should have 1.\\\n",
    "We solve this by just adding an empty axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "images = images[:, :, :, None]\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Now, you can build your own network from scratch, and that's a useful exercise. We're going to skip that\n",
    "here, and use one of the popular, exisiting frameworks that are widely used in current research.\n",
    "The most used base frameworks are [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), and [Keras](https://keras.io/). Keras is a high-level API that abstracts a large amount of the process of building,\n",
    "training, and testing a model. You will need either TensorFlow or PyTorch, and the Keras API will automatically\n",
    "detect which base framework you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary TF models and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Sequential model, and add layers to it.\n",
    "model = Sequential()\n",
    "\n",
    "# The model we build here is the one that has currently performed best when classifying the detector images.\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation = 'relu', input_shape= (16,16,1)))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6, 6, 128)         8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 4609      \n",
      "=================================================================\n",
      "Total params: 31,745\n",
      "Trainable params: 31,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Once the model is built, we need to compile it. This is where we specify the loss function,\n",
    "# optimizer, and any metrics we need, even custom ones.\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This is the point where we normalize our data, just as we pass it to the training function of the model.\n",
    "The training run will display the progress as it goes through each batch.\n",
    "$$ \\text{num_batches} = \\frac{\\text{num_samples}}{\\text{batch_size}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the training.\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6750 samples, validate on 2250 samples\n",
      "Epoch 1/20\n",
      "6750/6750 [==============================] - 4s 531us/step - loss: 0.2238 - accuracy: 0.9176 - val_loss: 0.5157 - val_accuracy: 0.8151\n",
      "Epoch 2/20\n",
      "6750/6750 [==============================] - 4s 537us/step - loss: 0.2318 - accuracy: 0.9124 - val_loss: 0.6069 - val_accuracy: 0.7800\n",
      "Epoch 3/20\n",
      "6750/6750 [==============================] - 4s 528us/step - loss: 0.2272 - accuracy: 0.9157 - val_loss: 0.3950 - val_accuracy: 0.8644\n",
      "Epoch 4/20\n",
      "6750/6750 [==============================] - 4s 538us/step - loss: 0.2180 - accuracy: 0.9196 - val_loss: 0.6387 - val_accuracy: 0.7818\n",
      "Epoch 5/20\n",
      "6750/6750 [==============================] - 4s 531us/step - loss: 0.2218 - accuracy: 0.9197 - val_loss: 0.5199 - val_accuracy: 0.8240\n",
      "Epoch 6/20\n",
      "6750/6750 [==============================] - 4s 538us/step - loss: 0.2071 - accuracy: 0.9255 - val_loss: 0.5775 - val_accuracy: 0.8067\n",
      "Epoch 7/20\n",
      "6750/6750 [==============================] - 4s 536us/step - loss: 0.2138 - accuracy: 0.9233 - val_loss: 0.4275 - val_accuracy: 0.8578\n",
      "Epoch 8/20\n",
      "6750/6750 [==============================] - 4s 538us/step - loss: 0.2000 - accuracy: 0.9289 - val_loss: 0.5618 - val_accuracy: 0.8164\n",
      "Epoch 9/20\n",
      "6750/6750 [==============================] - 4s 540us/step - loss: 0.2160 - accuracy: 0.9209 - val_loss: 0.5182 - val_accuracy: 0.8253\n",
      "Epoch 10/20\n",
      "6750/6750 [==============================] - 4s 532us/step - loss: 0.1983 - accuracy: 0.9286 - val_loss: 0.6606 - val_accuracy: 0.7818\n",
      "Epoch 11/20\n",
      "6750/6750 [==============================] - 4s 567us/step - loss: 0.1932 - accuracy: 0.9319 - val_loss: 0.2550 - val_accuracy: 0.9147\n",
      "Epoch 12/20\n",
      "6750/6750 [==============================] - 4s 537us/step - loss: 0.2008 - accuracy: 0.9302 - val_loss: 0.5304 - val_accuracy: 0.8267\n",
      "Epoch 13/20\n",
      "6750/6750 [==============================] - 4s 552us/step - loss: 0.1935 - accuracy: 0.9338 - val_loss: 0.6535 - val_accuracy: 0.7880\n",
      "Epoch 14/20\n",
      "6750/6750 [==============================] - 4s 538us/step - loss: 0.1980 - accuracy: 0.9292 - val_loss: 0.9176 - val_accuracy: 0.6942\n",
      "Epoch 15/20\n",
      "6750/6750 [==============================] - 4s 546us/step - loss: 0.1988 - accuracy: 0.9293 - val_loss: 0.6634 - val_accuracy: 0.7844\n",
      "Epoch 16/20\n",
      "6750/6750 [==============================] - 4s 543us/step - loss: 0.1987 - accuracy: 0.9316 - val_loss: 0.5481 - val_accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "6750/6750 [==============================] - 4s 538us/step - loss: 0.1809 - accuracy: 0.9379 - val_loss: 0.4184 - val_accuracy: 0.8733\n",
      "Epoch 18/20\n",
      "6750/6750 [==============================] - 4s 532us/step - loss: 0.1854 - accuracy: 0.9357 - val_loss: 0.4585 - val_accuracy: 0.8547\n",
      "Epoch 19/20\n",
      "6750/6750 [==============================] - 4s 567us/step - loss: 0.1848 - accuracy: 0.9354 - val_loss: 0.4594 - val_accuracy: 0.8578\n",
      "Epoch 20/20\n",
      "6750/6750 [==============================] - 4s 533us/step - loss: 0.1825 - accuracy: 0.9370 - val_loss: 0.4120 - val_accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f500c693dd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting validation data requires a tuple (val_input, val_targets). You can also just pass the\n",
    "# entire training set without splitting, and specify validation_split instead of validation_data.\n",
    "# The the model handles the splitting.\n",
    "\n",
    "val_data = (normalize_image_data(images[val_idx]), labels[val_idx])\n",
    "model.fit(\n",
    "    x=normalize_image_data(images[train_idx]),\n",
    "    y=labels[train_idx],\n",
    "    validation_data=val_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.argmax(axis=-1)\n",
    "tmp_predicted = loaded_model.predict(x_test)\n",
    "y_pred = tmp_predicted.argmax(axis=-1)\n",
    "\n",
    "# indices, relative distances and relative energies for test set\n",
    "single_indices, double_indices, close_indices = event_indices(test_positions)\n",
    "rel_distance_test = relative_distance(test_positions)\n",
    "energy_diff_test = energy_difference(test_energies)\n",
    "rel_energy_test = relative_energy(test_energies, noscale=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some numbers from results\n",
    "Mean separation distances, mean relative energies, events with separation < 3mm etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "The confusion matrix can be a useful metric to gain a little bit\n",
    "more insight into specifically what the model gets wrong.\n",
    "* Top left: Single events classified as single events\n",
    "* Top right: Single events classified as double events\n",
    "* Bottom left: Double events classified as single events\n",
    "* Bottom right: Double events classified as double events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from analysis_functions.plotting import plot_confusion_matrix\n",
    "classes = [\"single\", \"double\"]\n",
    "title = net +\" Confusion Matrix\"\n",
    "plot_confusion_matrix(y_true, y_pred, classes, title=title)\n",
    "plt.show()\n",
    "#plt.savefig(FIGURE_PATH+net+\"_confmat.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(y_true, y_pred)\n",
    "print(\"F1-score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves\n",
    "#### All events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from analysis_functions.plotting import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plot_roc_curve(y_true, tmp_predicted[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Area under curve:\",roc_auc_score(y_true, tmp_predicted[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_close_true = np.concatenate((y_true[single_indices], y_true[close_indices]), axis=0)\n",
    "single_close_pred = np.concatenate((tmp_predicted[single_indices,1], tmp_predicted[close_indices,1]), axis=0)\n",
    "plot_roc_curve(single_close_true, single_close_pred)\n",
    "plt.show()\n",
    "print(\"Area under curve:\",roc_auc_score(single_close_true, single_close_pred))\n",
    "single_close_pred = np.concatenate((y_pred[single_indices], y_pred[close_indices]), axis=0)\n",
    "score_close = f1_score(single_close_true, single_close_pred)\n",
    "print(\"F1-score close: \", score_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions and scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing correct and misclassified double events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, np.amax(energy_diff_test), 0.02)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of separation distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Separation distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, 10, 0.1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "#ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of Relative distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Relative distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "#ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "#ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot relative distance vs. relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    rel_distance_test[double_indices][wrong_doubles], \n",
    "    rel_energy_test[double_indices][wrong_doubles],\n",
    "    marker='.',\n",
    "    )\n",
    "plt.title(\"Separation distance vs. relative energy for misclassified double events\")\n",
    "plt.xlabel(\"Separation distance [mm]\")\n",
    "plt.ylabel(\"Relative energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events with high separation distance\n",
    "and varying relative energy above a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the indices\n",
    "separation_lim = 20.0\n",
    "energy_lim = 0.2\n",
    "high_relD = np.where(rel_distance_test[double_indices][wrong_doubles] > separation_lim)[0]\n",
    "high_relE = np.where(rel_energy_test[double_indices][wrong_doubles] > energy_lim)[0]\n",
    "\n",
    "# Then get the overlapping indices\n",
    "high_both = np.array(list(set(high_relD).intersection(set(high_relE))))\n",
    "print(\"Found {} events.\".format(len(high_both)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the indices to fetch the images and other statistics we want.\n",
    "images_plot_high = images[test_idx][double_indices][wrong_doubles][high_both][:,:,:,0]\n",
    "rel_pos_plot_high = rel_distance_test[double_indices][wrong_doubles][high_both]\n",
    "rel_energy_plot_high = rel_energy_test[double_indices][wrong_doubles][high_both]\n",
    "energy_plot_high = energies[test_idx][double_indices][wrong_doubles][high_both]\n",
    "\n",
    "# Plot the events images with relative separation, energies, and relative energy\n",
    "# to the top left of each image\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12,12))\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        if i*2+j >= len(high_both):\n",
    "            fig.delaxes(ax.flatten()[i*2 + j])\n",
    "            continue\n",
    "        ax[i, j].imshow(images_plot_high[i*2 + j])\n",
    "        rel_pos = rel_pos_plot_high[i*2 + j]\n",
    "        rel_E = rel_energy_plot_high[i*2 + j]\n",
    "        E1 = energy_plot_high[i*2 + j, 0]\n",
    "        E2 = energy_plot_high[i*2 + j, 1]\n",
    "        relp = \"dist = {:.2f}mm\".format(rel_pos[0])\n",
    "        rele = \"rel_E = {:.2f}\".format(rel_E[0])\n",
    "        e1_txt = \"E1 = {:.2f} MeV\".format(E1)\n",
    "        e2_txt = \"E2 = {:.2f} MeV\".format(E2)\n",
    "        ax[i, j].text(-10, 0, relp, fontsize=11)\n",
    "        ax[i, j].text(-10, 1, e1_txt, fontsize=11)\n",
    "        ax[i, j].text(-10, 2, e2_txt, fontsize=11)\n",
    "        ax[i, j].text(-10, 3, rele, fontsize=11)\n",
    "        \n",
    "fig.suptitle(\"Misclassified events with large separation distance\", fontsize=16)\n",
    "#fig.savefig(FIGURE_PATH+net+\"_misclassified_large_dist.pdf\", format=\"pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of events that no networks were able to classify correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indices\n",
    "OUTPUT_PATH = MODEL_PATH = \"../../data/output/\"\n",
    "fname_indices = \"never_correct_indices_rerun.txt\"\n",
    "never_correct = np.loadtxt(OUTPUT_PATH + fname_indices, dtype=int).tolist()\n",
    "\n",
    "rel_distance_all = relative_distance(positions)\n",
    "rel_energy_all = relative_energy(energies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions for relative distance and relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bins\n",
    "dist_bins = np.arange(0, np.amax(rel_distance_all), 0.5)\n",
    "energy_bins = np.arange(0, np.amax(rel_energy_all), 0.02)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "ax[0].hist(rel_distance_all[never_correct], bins=dist_bins)\n",
    "ax[0].set_title(\"Distribution of relative distance\\n for always misclassified events\")\n",
    "ax[0].set_xlabel(\"Relative distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(rel_energy_all[never_correct], bins=energy_bins)\n",
    "ax[1].set_title(\"Distribution of relative energy\\n for always misclassified events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "\n",
    "#fig.savefig(FIGURE_PATH+net+\"_relative_noncorrect.pdf\", format=\"pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images of some of the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of always misclassified events:\", len(never_correct))\n",
    "\n",
    "images_plot = images[never_correct][:,:,:,0]\n",
    "rel_dist_plot = rel_distance_all[never_correct]\n",
    "rel_energy_plot = rel_energy_all[never_correct]\n",
    "energy_plot = energies[never_correct]\n",
    "fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "index = 10\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].imshow(images_plot[index + i*3 + j])\n",
    "        rel_dist = rel_dist_plot[index + i*3 + j]\n",
    "        rel_energy = rel_energy_plot[index + i*3 + j]\n",
    "        E1 = energy_plot[i*3 + j, 0]\n",
    "        E2 = energy_plot[i*3 + j, 1]\n",
    "        rel_d = \"rel_dist = {:.2f}mm\".format(rel_dist[0])\n",
    "        rel_e = \"rel_E = {:.2f}\".format(rel_energy[0])\n",
    "\n",
    "        e1_txt = \"E1 = {:.2f} MeV\".format(E1)\n",
    "        e2_txt = \"E2 = {:.2f} MeV\".format(E2)\n",
    "        ax[i, j].text(0,-2, rel_d, color='black', fontsize=11)\n",
    "        ax[i, j].text(0,-1, rel_e, color='black', fontsize=11)\n",
    "        ax[i, j].text(0,1, e1_txt, color='cyan', fontsize=11)\n",
    "        ax[i, j].text(0,2, e2_txt, color='cyan', fontsize=11)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Images of always misclassified double events\", fontsize=16)\n",
    "#fig.savefig(FIGURE_PATH+net+\"_nocorrect_samples.pdf\", format=\"pdf\")\n",
    "\n",
    "fig.show()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some images, with electron origin positions\n",
    "%matplotlib inline\n",
    "\n",
    "images = images.reshape(images.shape[0],16,16)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # plot image\n",
    "        ax[i, j].imshow(images[index + i*3 + j])\n",
    "        \n",
    "        # plot origin of event\n",
    "        x = positions[index + i*3 + j, 0]\n",
    "        y = positions[index + i*3 + j, 1]\n",
    "        ax[i, j].plot(x, y, 'rx')\n",
    "        ax[i, j].set_title('single')\n",
    "        if positions[index + i*3 + j, 3] != -100:\n",
    "            x2 = positions[index + i*3 + j, 2]\n",
    "            y2 = positions[index + i*3 + j, 3]\n",
    "            ax[i, j].plot(x2, y2, 'rx')\n",
    "            ax[i, j].set_title('double')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of position around highest intensity pixel\n",
    "In previous work data analysis showed that most event positions are within the highest intensity pixel,\n",
    "and all (verify!) events are within the two highest intensity pixels,\n",
    "It might be reasonable to look at how the predicted positions are distributed around the highest intensity\n",
    "pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = images[single_indices].reshape(images[single_indices].shape[0],16,16)\n",
    "\n",
    "# get index of highest energy pixel\n",
    "print(np.unravel_index(np.argmax(imgs[0], axis=None), imgs[0].shape))\n",
    "fix, ax = plt.subplots()\n",
    "ax.imshow(imgs[0])\n",
    "ax.plot(0,0, 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"DATA_PATH\": \"../../data/real/anodedata.txt\",              \n",
    "    \"MODEL_PATH\": \"../../data/output/models/\",                \n",
    "    \"CLASSIFIER\": \"Project-0.97.hdf5\",                      \n",
    "    \"SINGLE_ENERGY_MODEL\": \"single_energy_model_name.hdf5\",    \n",
    "    \"SINGLE_POSITION_MODEL\": \"single_position_model_name.hdf5\",\n",
    "    \"DOUBLE_ENERGY_MODEL\": \"double_energy_model_name.hdf5\",    \n",
    "    \"DOUBLE_POSITION_MODEL\": \"double_position_model_name.hdf5\" \n",
    "}\n",
    "\n",
    "data = import_real_data(config)\n",
    "print(data['image'].type)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
